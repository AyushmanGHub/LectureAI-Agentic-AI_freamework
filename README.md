# LectureAI - your personal AI tutor

# ğŸ“ LectureAI â€“ Your Personal AI Tutor

**Summer 2025 Internship Project**<br>
**Topic:** AI Agents for Automation of Tasks<br>
**Lab:** Algo Lab<br>
**Team:** Ayushman Anupam, Tejaswi Sherawat<br>
**Mentors:** Animesh Guchhait, Chandrashish Prasad, Hithesh KK, Rahul Shah

## ğŸ“– Overview

### Problem Statement

The rapid growth of educational videos in the last decade has led to challenges such as:

* **Linear Information Flow** â€“ Hard to jump to exactly what you need.
* **Information Overload** â€“ Too much content without smart filtering.
* **Time-Consuming Search** â€“ Manual scrolling to find relevant sections.
* **Limited Interaction** â€“ No real-time Q\&A or contextual summaries.
* **Workflow Breaks** â€“ Needing to leave the platform for missing info.
* **No Personalized Feedback** â€“ No way to measure understanding or progress.

### Our Solution

**LectureAI** takes video lecture and transforms it pssive watching into an **interactive, insightful, and personalized learning experience** using an **agentic AI framework**.
With specialized AI agents, it allows users to:

* Ask contextual questions directly about the video.
* Get timestamp-based explanations.
* Generate quizzes (MCQs) with detailed evaluation.
* Create mind maps and structured notes.
* Explore beyond-video knowledge using web search.


## ğŸš€ Summary of the App & Feature Highlights

* **ğŸ¯ AI-Powered Chatbot** â€“ Uses **Retrieval-Augmented Generation (RAG)**, timestamp finders, and explainers to answer queries with context.
* **ğŸ“ MCQ Generation & Evaluation** â€“ Auto-creates quizzes with scoring, explanations, and difficulty breakdown.
* **ğŸ§  Mind Map Creation** â€“ Converts video transcripts into a **Graphviz-powered** visual map of topics.
* **ğŸ“š Notes Generation** â€“ Creates structured notes with an introduction, key takeaways, and conclusion.
* **ğŸ” Multi-Agent Architecture** â€“ Central LLM-based controller picks the right agent for each task, with a validation layer for accuracy.
* **âš¡ Resource Creation Pipeline** â€“ Automatically extracts raw transcripts, semantic chunks, and time-bounded chunks to power all features.


## ğŸ›  Technologies Used

* **Programming Language:** Python
* **AI & NLP:**

  * LLM APIs (OpenAI, Hugging Face)
  * Embedding Model: `mixedbread-ai/mxbai-embed-large-v1`
  * Whisper for transcription
* **Frameworks & Libraries:**
  * Langraph for LectureAI (Agentic AI framework)
  * LangChain for MCQ workflows
  * Graphviz for mind map rendering
  * ffmpeg for audio extraction
* **Search & Retrieval:** Vector Store (FAISS)
* **APIs & Tools:** Tavily Search API, RAG pipelines

---

## ğŸ¤ Letâ€™s Connect!

ğŸ˜Š Iâ€™m always open to meaningful conversations, collaborative projects, and idea exchanges in the fields of **graph theory**, **machine learning**, and **data science**.
If youâ€™re interested in discussing new insights, working together on related topics, or contributing to ongoing discussions â€” feel free to reach out!
**Letâ€™s learn and build together ğŸš€**
nt me to also create a **diagram-based workflow section** for the README so it visually matches your reportâ€™s workflow figure? That would make your GitHub page much more engaging.

